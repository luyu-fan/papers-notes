## Introduction

这里主要对细粒度分类图像做一个汇总，按照时间顺序关系列出表格，主要记录使用的方法，解决的问题，最终的效果等。针对有价值的，需要仔细阅读研究的，会单独给出链接再次引入。

### FGVC论文汇总

| 时间 |     会议      |                             题目                             |                         想解决的问题                         |                          使用的方法                          |                             结果                             |                           训练细节                           |                             其它                             |
| :--: | :-----------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 2015 |     CVPR      | Fisher Vectors Meet Neural Networks: A Hybrid Classification Architecture | FV方法和CNN方法是两种比较典型的图像分类pipeline，前者比较快速，后者精度比较高，想把这两种方式结合起来。 | 首先使用一个FV层进行无监督学习，利用SIFT算子抽取特征，然后跟着一个MLP使用BP训练。MLP在编码以及整合的多个步骤是共享的，因此需要探讨利用这种方式对卷积学习到的特征进行编码是否真的有效。另外一个就是FV后面都是跟着一个线性分类器，当后面跟着一个非线性分类器的时候是否有效果提升。 |         与传统的FV类方法相比取得了比较大的效果提升。         | 在ILSVRC数据集上进行训练，非深度学习类训练方法。未提及学习率之类的设置参数。 | 中间产生的特征维度是有4K那么多个。维度比较高。这种方法也是一种比较老的方法。 |
| 2017 |     TPAMI     |      Bilinear CNNs for Fine-grained Visual Recognition       | 模拟人类的视觉处理机制，同时捕获位置和语义信息，通过双流网络和特征外积来融合特征和位置信息。 | 局部模型高效性的原因：作者声称局部推理的高效性在于其与物体的位置及姿态无关，纹理表示通过图像特征进行无序组合的设计，从而获得平移无关性。希望两个特征能分别表示图像的位置和对图像进行识别。在结构上，由于2个CNN提取的特征，进行外积得到得到多个不同的组合。 |       使用224 * 224大小进行训练，得到84.1%的最高精度。       |                          未详细描述                          | 进行了多种实验方法对比，包括一般的FV方法和与CNN结合的方法。  |
| 2018 |     CVPR      | Learning a Discriminator Filter Bank within a CNN for Fine-grained Recognition | 通过学习一组能够捕获和类比相关的最具判别力的区域来增强分类结果。核心是想通过1*1卷积学习中级语义表示，每一个1 X 1的卷积核可以堪称是一个patch的检测器。 | 通过学习一组卷积核，来捕捉那些比较好的与类别相关的中级语义信息，这些可以通过监督学习的多流网络结果以及非随机初始化通过监督学习得到。最终就可以得到一组与类比相关的那些独特的卷积核，一般的端到端的网络结构目的都是增强中级表示的学习能力。而且这个过程会迫使网络会关注于对象之间共有的特征，并且会增强最具区分能力区域的学习。网络结构中主要有三部分组成，一部分为对称的双流结构来学习到那些比较独特的特征patches. <br />主要需要学习的是在1 * 1 卷积核的设置上并不是随机的，而是根据之前的预训练模型来设置1 x 1卷积核，而且每个类别都对应了多个卷积核。<br />损失构建方面，分为了三个分支，一个是和普通分支一样的全局分支用来捕获全局信息，另外一个是用来学的k个独特区域的池化分支，然后还有一个跨通道池化的监督分支。最后加权获得损失。 | 输入448 * 448，87.4%。ResNet50作为backbone.训练阶段采用不同的权重损失。 |                      训练细节没有提及。                      | 提出了为每一个类别学习最佳的区分特征，但是显然这个依然是只考了最具备判断力的那些区域。 |
| 2018 |     ECCV      |  Pairwise Confusion for Fine-Grained Visual Classification   | 为了解决种间的相似性问题，即更好地区分更相似的物种。对一般的交叉熵损失进行一个正则化限制。 | 绝大多数的方法主要关注于怎么解决姿势、光照、视角的相关性问题，很少提及到种间物种的相似性问题，如果像LSVC那样只使用交叉熵来优化，由于真实目标的极度相似，就会导致网络学习到那些sample-specific的假知识来尽可能降低训练损失，从而很快地过拟合。<br />因此通过混淆网络的输出来使得网络学习到那些轻微相似的但具备判别能力的特征，从而更好区分相似度高的类别，这一点通过最小化不同样本之间输出分布的距离来实现，不需要额外的参数量以及训练成本的增加。<br />考虑到样本之间的对称型，作者证明了采用欧式距离这一种不常用的用来衡量分布距离的评估标注（常用的是KL散度、JS散度等）。<br />这一点可以通过矩阵形式实现，在假设样本数目相等的情况下，这个和另外一个著名的公式能量距离就非常相似。 |                            86.24%                            | 采用了GPUs集群来训练。没有提及是怎么训练的。采用了Grad-CAM来可视化那些经过混淆之后的关注区域。 | 提到了采用欧式距离来计算两个分布之间的距离，虽然效果不是很好，但是有证明，以后用的时候可以引用。 |
| 2018 |     NIPS      |         Maximum Entropy Fine-Grained Classification          |      利用对输出概率分布的最大熵学习来获得比较好的特征。      | 如果目标对象的前景和背景差的比较多，那么网络记住背景来分类的成本是要比记住前景信息小得多的，所以交叉熵会使得网络记住那些和背景来做区分。对于CNN最终产生logits的另一种理解，CNN最终产生logit概率分布的熵其实代表了CNN置信度或者是挑选能力的一个测度。如果熵比较高，那么就会降低这个模型的置信度，从而在有限的细粒度数据下学的比较好的特征。 |            86.54%，使用DenseNet161. Titan X GPUs             |                      训练细节没有提及。                      | 虽然模型效果比较差，主要关注于最大熵公式的推导比较多，也评估了特征丰富度，主要还是偏理论推导。 |
| 2019 |     CVPR      | Weakly Supervised Complementary Parts Models for Fine-Grained Image Classification from the Bottom up | 挖掘和利用除了占据主导低位的区分区域之外其它那些补充的次要区域。然后通过LSTM综合各个部分特征。 | 大致流程，只需要给定图像及其类别标签。首先通过弱监督提取粗糙的实例然后使用Mask-RCNN和CRF-based分割进行实例分割。然后在保持特征多样性的前提下搜索那些多样性最多的区域，然后利用双向LSTM融合主要特征区域和补充特征区域，完成最后的分类。<br />具体操作上分为两个大的步骤，第一个包含的工作为首先训练一个深度分类网络，用来产生CAM， 通过CAM得分作为每个像素的分割时的概率得分，接着使用条件随机场与低层的表征信息合作来进行无监督分割。然后使用Mask RCNN来进行细化分割，并且这两步可以循环迭代，直到产生最后的分割结果。<br />接着根据上面的结果产生的多个候选区域，将其形成补充对象区域。 |                          90.4% CUB                           | 分割初始阶段的学习率为0.001，每隔40000次更新衰减为原来的十分之一，使用SGD优化，使用了BN层，训练70000次迭代。在之后的Mask RCNN阶段和FPN一起进行细化。将最小边设置为800像素。 | 过程明显分为多个阶段，而且，这明显是显卡和模型一起堆上去的吧。 |
| 2019 |     NIPS      | Learning Deep Bilinear Transformation for Fine-grained Image Representation | 一般的基于Part的那些方法关注于那些语义注意力，然后训练数个互为补充的最具判断力的区域来进行分类，声称这样做不能完全发挥端到端的潜力。双线性特征转换是通过在全局图像上以全连接的形式计算通道之间的交互信息得到的。 | 通过在最具区分性的通道上计算双线性转换来提升分类精度同时降低外积时的计算量。首先，语义分组层根据不同的语义信息将输入通道特征映射为多个不同的组，因此，最具判别力的某一个特定的语义特征就和这一个组联合在一起。这样的表示就能在组与组之间的双线性操作被进一步加强。<br />通过学习一组权重进行通道的分组。 |                            85.1%                             |             在ResNet50上进行训练，448 x 448, SGD             |           核心思想就是将通道分组然后在双线性池化。           |
| 2019 |     CVPR      | Destruction and Construction Learning for Fine-grained Image Recognition | 认为人类专家识别图像的过程是由部分决定的，只看见部分的图像就可以识别出原始类别是什么，使网络更关注于那些更具备区分性的区域patch。 | 做法就是在标准的分类骨架同时还有一个摧毁和重建网络来打乱原始图像以及根据打乱的原始图像进行重建，为了这种机制带来的噪音效果，使用了对抗损失区分是原图还是打乱后的来降低这种影响。对于重建分支，使用一个区域对齐网络来尝试恢复原始图像中的结构信息，使得网络关注于块和块之间的相关性信息。最终将这些细节信息注入到分类网络中。<br />损失构成主要有三部分，一部分是销毁部分的损失，用于让网络学习到关键的细节信息用于最后的分类任务，一部分是对抗性损失，用于抵消因打乱结构造成的人工边缘，最后一部分就是重建损失，用于捕获区域和区域的相关性联系。 |                            87.8%                             | 使用ResNet50作为backbone, 输入尺寸为448 x 448。所有的模型训练了180轮，学习率每60轮衰减为0.1倍，测试的时候只需要保留分类分支即可。没有说明使用何种优化器以及学习率调度器。 | 也是强调网络应该关注那些区域信息，使用摧毁与重建思想来完成训练。 |
| 2019 |     AAAI      | Fine-Grained Visual Classification with Batch Confusion Norm | 将对与对之间的混淆能量作为正则化引入到一个批次当中去来提升网络学习。 | 核心思想是在细粒度学习过程中注入轻微的分类混淆，以促使网络能努力学习到细节区分性区域来做出更正确的判断。使用的方法就是降低一个批次中预测矩阵的秩。<br />这个地方使用最小化核范数来近似最小化矩阵的秩，进而转化为求解奇异矩阵的秩的求解问题。<br />然后又在后面加了一个门控ASPP网络，从中捕获更关键的区分性区域，利用ASPP机制来抽取不同视角下的特征，使用两个并行ASPP分支，一个抽取特征，一个获得注意力。<br />损失部分主要有交叉熵分类损失和批混淆正则化两部分构成。 |                          89.2%，CUB                          | 使用ResNet50为骨架，resize to 600 and crop to 448, SGD优化，初始学习率为0.008，后者正则化的权重为10，批大小为16，是余弦退火算法调度学习率。但没有说明其中的参数。训练了200轮次。 |            其中可视化的地方做的比较好。比较详细。            |
| 2019 |     ICCV      |   Cross-X Learning for Fine-Grained Visual Categorization    | 认为前面的方法都是集中于学习特定部分的特征、互相隔绝的特征，忽略了不同图像之间的相关性。因此论文提出关注于不同网络层、不同图像之间的相关性及语义的关系。 | 首先获得全局平均池化得到全局向量，然后利用这些全局特征获取不同图像之间的特征关系。使得某个图像的特征和其它特征离得尽可能远。使用Frobenius范数以及对角阵向量的二范数平方。使用了特征金字塔来融合各个不同阶段的特征，而且还使用了卷积来完成抗锯齿操作。<br />在层和层之间使用KL散度来衡量输出分布之间的距离，即每一层都需要输出并得到分类的概率向量。<br />最终优化项为各个正则项以及层与层之间距离损失之和。 |                          87.7% CUB                           | 使用ResNet50以及SENet为骨架，后面接自己的模块。使用SGD优化器，动量为0.9，以及批大小为32，初始学习率为0.01，一共训练了30轮，每15轮降低为0.1倍。对于没有提供验证集的数据集，从训练集中划分10%的数据集合作为开发验证集合。 | 采用SeNet中的通道注意力机制实现多个注意力模块。最后将各个阶段的分类结果联合起来得到最终的输出。在一些论文中提到了如何利用多个层之间的特征。 |
| 2019 |     ICCV      | Selective Sparse Sampling for Fine-Grained Image Recognition | 核心目的依然是捕获多个多样的细节区域，从类别响应图中收集局部最大值，来估计最佳信息含量的感受野，并且学习一个稀疏注意力集合在保持语义信息的情况下放大细节区域。最终由一个最具区分性的特征和多个补充性的特征来构建分类。 | 首先从类别响应图CAM中收集响应尖峰，即局部最大点，从而计算出输入图像中蕴含由最佳信息的感受野，然后估计每一个尖峰响应在原图中的尺寸，之后通过不均匀的变换突出感受野中的那些相关细节区域，来指引模型学习最具区分性特征和补充性特征。<br />根据CAM的计算方式，如果最大的那个类别产生的MAP一般不一定是最大的尖峰区域，所以可以采用top-5的和来保证召回率。<br />根据得到的尖峰响应来划分最佳区域和补充区域，最终得到两个映射图。<br />根据上面得到的两个特征图，进行非均匀缩放图像，然后再进行分类。 |                          88.5% CUB                           | 将所有图像缩放到448 x 448大小，使用ResNet50作为backbone, 批大小=16，训练了60轮，SGD，动量为0.9，权重衰减为1e-4，对于backbone部分使用学习率为0.001，其它部分为0.01. | 值得学习的点就是那个从类别激活图中获取尖峰然后再进行非均匀图像变换。过程很精妙，用到了高斯核。而且从结果上看这样做直到训练的最后多个关注区域都会保持。 |
| 2020 |     CVPR      | Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization | 利用树的组织形式来学习由粗到细的特征信息，最后在各个叶子节点来捕获那些细节信息，进行最终的分类，根据路由模块完成相关特征筛选。 | 整个网络结构主要分为四个部分，分别是基础的backbone，然后是路由部分，然后再接着一个注意力的transformer，然后就是标签预测模块。<br />在基础骨架部分，为了使用比较小的感受野也捕获那些细节信息，所以声称采用了比较浅层的模型，即只使用前面的网络部分。<br />在路由模块，主要是用来决定会将特征送到哪一个子分支里面，这个由一个1 x 1的卷积层和SeNET以及non-local块构成，而且二者共享了融合步骤。然后，使用了全局平均池化、全连接以及sigmoid激活，决定这个样本被送往哪一个分支。<br />注意力转换，用来强化网络从而可以捕捉到那些更具区分性的去区域，因此使用了ASPP结构来捕获感受野信息。然后就在这些层后面各种加东西。<br />之后就是一个标签预测层，从每个叶子节点产生最终的概率分布。 |                          88.1% CUB                           |                     SGD, 各种神奇的参数                      | 这个文中感觉主要的新意就是利用二叉树与神经网络在一起，而且对于概率分类的解释也比较好，但是感觉就是纯粹的堆积，没有什么借鉴意义。 |
| 2020 | CVPR Workshop | Focus Longer to See Better: Recursively Refined Attention for Fine-Grained Image Classification | 从全局分支和局部裁剪分支两个部分共同入手，分别捕获全局信息和局部信息，联合表示。进行最后的分类。 | 本质上就是两个分支，一个全局分支，一个part分支，两个联合起来分类，目测应该需要使用标注数据。之后对于局部分支还使用了LSTM来捕获注意力特征，并且将LSTM之后得到的特征和每一个时间步所对应的权重相乘再相加，得到最终的注意力特征。权重是通过指数加权的形式获得。 |                            79.7%                             |                         无参考价值。                         |                         无参考价值。                         |
| 2020 |      ——       | Multi-Branch and Multi-scale Attention  Learning for Fine-Grained Visual Categorization | 从粗到细，层层捕获关键性特征。粗粒度，对象粒度，以及部分粒度三个分支层层递推，最终获得比较好的表示结果。 | 首先按照一比一融合特征信息，根据特征激活图中值的大小从中根据与均值相比筛选出比较高的区域，从而确定一个大致的目标位置，接着裁剪再进行输入到网络中，然后在滑窗中操作，得到比较细的区域中的那些均值，从而得到若干个比较细的部分。然后再裁剪出来进行分类。最终的损失就是将三个部分分类，然后全加起来。 |                            89.6%                             | 使用不同尺寸大小的窗口，全在最后最高级的那一层上座。ResNet50。SGD,0.9, 权重衰减1e-4,Batch为6，初始学习率为0.001，每60轮衰减为原来的0.1倍，训练越200轮。 | 这里用到了一比一特征融合和窗口筛选平均值，只在最后一层进行相关操作。 |
| 2020 |     AAAI      | Learning Attentive Pairwise Interaction for Fine-Grained Classification | 思想是模拟人类识别过程，通过对比学习循序渐进的方式来获得那些输入对之间的突出不同之处。 | 通过循序渐进对比的方式来识别两幅图像，获得不同之处。整个网络由三部分构成。<br />首先是交互向量的学习，门控向量的学习以及对与对之间的交互。<br />首先，交互向量总结了两个样本之间的对比性信息提示，然后将其与独立的每个全局样本进行比较，从而为每个样本生成门控向量从而强调那些语义区别，这些门控单元实际上就是注意力机制。每张图像就可以生成两张不同的门控单元，一个是自己的另外一个是pair的，但最终的分类结果都是属于这个类的。<br />所谓交互向量的学习实际上就是将CNN之后得到的特征联合起来然后再通过全连接层来获得，利用得到的交互向量和原始向量做一个点乘，再通过sigmoid，作为每一个特征的门控权重。利用门控以及全局向量，就会得到对应的注意力特征，然后进行分类。<br />损失方面，除了最基本的交叉熵损失之外，还有在self和other之间输出分别的一个score ranking regularization. 使用hinge loss作为输出分布的距离损失，二者的距离应该比某一个埃普西隆值大，这样才能更好地表明这个门控向量起到作用。 |                          90.0%，CUB                          | 首先将图像resize到512 x 512, 然后从中裁切出448 x 448大小子图，使用ResNet101作为backbone. 在训练的时候，每个批次里面随机选择30个类别，然后从每个类别中随机选择4个样本，每个样本选择的时候从中寻找与其最相近的样本，根据特征的欧式距离来决定。这样就构建起了最近的类内样本对和类间样本对。<br />埃普西隆的值为0.05，使用SGD，mom = 0.9, wd = 5e-4, 使用余弦退火方法。初始学习率为0.01，训练总轮数为100，刚开始先freeze前面的卷积层，只训练后面的全连接层。 | 通过对比学习的方式来学习样本对之间的差异，根据差异做出区分。有一个很明显的特点，那就是在不同的backbone上取得了最好的结果，这是一个不公平的。 |



