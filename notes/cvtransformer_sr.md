## Transformer in SR

### 简介

使用LR和Ref Images作为key和value对训练transformer，使其能够学习比较好的特征恢复能力。需要注意的是，SR一般有两种Paradigm，即单幅图像的SISR和基于参考的RefSR. 

传统的SISR通常会造成比较模糊的结果，原因是高分辨率纹理在降采样过程中被严重损坏了，不但很难恢复，而且往往是二义性的。

近期RefSR被广泛关注，即从一个参考图像中搜索并选择合适的HR纹理来生成视觉上比较令人满意的结果。一般的SOTA方法会存在视角变换无法搜索出正确纹理。

### 核心思想

利用transformer学习比较好的hard-attention和soft-attention. 主要有4部分组成，第一部分包括了特征抽取器，主要从LR图像和Ref中抽取特征。然后学习一个相关嵌入模块，即transformer模块，将LR中的特征作为key, 将Ref中的图像作为key, 从而获得硬注意力和软注意力的映射。最后分别使用硬注意力模块看和软注意力模块和一个自注意力模块将从Ref图像中搜索、转化和融合HR特征到LR图像中。

最后还学到了一个跨尺度的特征整合模块，从不同的尺度中学习到更富表现力的特征。 

### 方法模型

### 训练细节

### 其它

