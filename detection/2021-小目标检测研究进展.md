## 小目标检测研究进展

#### 小目标定义及难点

##### 定义

1. 绝对尺寸： 32 * 32 ， 50 * 50
   1. 人眼的生理原因
   2. 降采样原因
2. 比例值为0.1 / 面积开方值小于0.03
3. 实际的应用场景

##### 挑战

1. 可利用特征少

   显然低分辨率的图像或者特征图从中能够获得的细节自然就更少。难以提取到具有鉴别力的特征，并且极易受到环境因素的干扰，进而导致了检测模型难以精准定位和识别小目标。

2. 定位精度要求高

   小目标在图中的覆盖面积小，边界框的定位相对于大、中尺度更难检测。任何一个像素点预测的偏差所导致的结果偏移的影响度大于大目标。锚框机制下这种偏移量所带来的影响更严重。

3. 现有数据集中小目标占比少

   主流的检测数据集中小目标的样本数量非常少。比较少关注这些特定目标。分布不均匀。小目标对于标注误差更敏感。小目标也存在于特定的场景。小目标的检测性能是要比通用的检测性能要差很多。

4. 样本不均衡

   锚框机制下的正负样本不均衡和样本级别下的类别不均衡。在混合样本中还会出现大小目标数量的不均衡。

5. 小目标聚集

   小目标之间有很大的概率会发生聚集，并且很可能会包含在大目标或者中等目标的检测框之内，在nms的过程中就会被剔除导致漏检。同时如果聚集区域的小目标边界之间距离过近，边界框就难以回归难以收敛。

6. 网络结构

   通用的模型往往针对的是大中尺度的目标，这种模型和网络结构对于小目标的检测并没有特别的优化和设计之处。锚框设计对于小目标来说极不友好。多方面的原因，小目标的训练样本占比少，对于损失函数的贡献少，进一步减弱了对小目标的检测能力。

### 小目标的研究思路

##### 数据增强

各类增强方法，但是主要针对的是中等尺寸以上的目标进行的增强过程。**尺度匹配，复制增强，复制粘贴小目标的方式来增强训练样本数，提升性能**。自适应重采样策略，基于预训练的语义分隔网络对目标图像进行上下文的复制，解决简单复制过程中的语义上下文背景污染等问题。

甚至使用强化学习技术进行采样。

数据增强能够在一定程度上解决小目标信息量少，缺乏表观特征和纹理等问题，能有效提升网络的泛化能力，带来性能提升的同时也会增加计算成本。

##### 多尺度学习

网络层数和空间位置信息的权衡。小目标和常规的目标相比可利用的像素少，网络层数的加深小目标的特征信息与位置信息逐渐丢失，难以被检测到。导致小目标的检测必须要同时考虑浅层特征和深层次的语义信息。

多尺度能替身性能的原因是同时考虑了浅层的空间位置信息和高层的抽象语义信息。有效提升小目标的检测性能。但不可避免地增加了计算量。

1. 方法1： 使用不同的卷积核通过不同大小的感受野获取不同尺度的信息。计算成本高，感受野的范围有限。已经弃用。
2. 方法2： 空洞卷积和可形变卷积为这种通过不同感受野大小获取不同尺度信息。使用的场景比较多。
3. 方法3： 图像金字塔，在同一个网络中输入不同尺度的图像获得一个金字塔特征。同样属于比较早期的方法。
4. 方法4：使用反卷积或者转置卷积来提升高level特征的分辨率。经典方法FPN. 结合了单一特征映射，金字塔特征层和综合特征的优点，最流行的多尺度网络。
5. 方法5(较新的方法)：上采样和skip连接，在训练过程中提取不同深度的特征，检测精度和速度都有所提升。
6. 方法6(针对高分辨率)：降低高分辨率图像的计算成本。提供了一种高分辨率检测网络，通过使用浅层网络处理高分辨率图像和深层网络处理低分辨率图像，做到权衡。甚至提出了使用专门的高分辨率金字塔来处理小目标。

可以看出：多尺度学习是解决小目标问题的关键方案。

##### 上下文学习

目标和场景、目标和目标之间会存在交互和依赖、约束关系。包含了两种：一种是基于隐式地上下文特征学习和基于显式地上下文推理的目标检测两个方面。

1. 隐式上下文。**目标周围的背景特征或者是全局的场景特征**。比如在每一个候选框生成一个较大的窗口，利用这个窗口内的特征作为上下文特征来增强目标的表征表示。甚至使用LSTM来捕获这个窗口内的上下文特征。设计上下文锚框，考虑到小目标上下文之间的交互信息，头和肩之间的信息等。

   针对全局语义信息，通过较大的感受野，卷积特征的池化这些操作将全局上下文看作是一种序列信息这三种方式来感知全局上下文。例如使用RNN来从不同的方向对整幅图像进行编码。

2. 显式上下文。利用场景中明确的上下文信息来推理。辅助推断目标的位置或者类别。考虑到加入先验知识，知识图谱等方法，外观几何约束

   深度学习下的显式上下文。这个和多尺度特征看起来又差不多。辅以注意力机制聚集于图像中的目标，充分利用目标的上下文信息，提升了实际场景中的小目标检测精度。

上下文学习的方法充分利用了图像中与目标相关的信息，能够有效提升小目标检测的性能。但没有考虑到场景中已经有的可能会出现的匮乏的问题。没有针对性地利用场景中的信息。

未来的方向：构建基于类别语义池的上下文记忆模型，通过利用历史记忆的上下文来缓解当前图像中上下文信息的匮乏的问题。基于图推理的方法。

##### 生成对抗式学习

**核心目的是通过低分辨率小目标的特征映射成和高分辨率等价的特征**，达到与尺寸较大目标的同等检测性能。提升小目标的特征的分辨率，缩小不同尺度目标的特征之间的差异。

具体做法是通过G和D相互对抗的方式来学习小目标的高分辨率表征的表示，首先G将小目标的表征转换为与真实大目标足够相似的超分辨率表征，同时判别器和生尘器对抗以识别生成的表征，对生成器施加条件要求，通过生成器和鉴别器相互对抗的方式来学习小目标的高分辨率特征表示。**图像的分辨率提升 --> 特征的分辨率提升**。

生成式方法的主要思想就是将小目标的特征分辨率通过超分技术进一步提升，从而得到比较好的结果。通过空洞卷积的方式使得生成的高分辨率目标特征和特征提取器之间保持相同的感受野大小，从而避免因感受野不匹配而产生错误超分特征的问题。

基于对抗网络的方法来提升小目标的检测看起来很自然，但是并不是那么直观，需要对特征进行上采样超分，利用生成对抗模型来超分小目标这一步骤看似不需要特别的结构设计，但是无法避免两个问题，一个式GAN的训练不稳定性，第二个是训练过程生成的多样性很有限。提升效果不是很明显。

##### 无锚框机制

首推的一种方法。

锚框的设计对小目标非常不友好。难以平衡小目标召回率和计算成本之间的矛盾。导致小目标的正样本与大目标的正样本之间极度不均衡。锚框机制需要引入非常多的超参数。锚框的数量、宽高比，大小等。难以训练。无锚机制成为新的研究热点。

###### 将目标检测任务转化为对关键点的预测上

两大类：基于角点。基于中心点。

A. 基于角点。通过对卷积特征图中学习到的角点分组来预测目标边界框。利用标注数据来训练卷积神经网络，利用这个网络来预测角点分布，然后利用角点分布和朴素贝叶斯来确定每个角点对象的候选区域是否包含目标。

典型的效果比较好的版本：CornerNet。 预测左上角和右下角，然后进行两两匹配。但不能很好地使用对象的语义信息。即角点的感受野中心并不在对象的中心上。

典型系列有：CornetNet, CenterNet-Triplet. ExtremeNet. 早期的方法

比较新的方法：

RepPoints: 提供了更细粒度的表示方式。使得目标可以被精细化界定。

FoveaBox: 直接预测目标存在的可能以及潜在目标的边界框等信息。首先预测目标存在的可能性，然后生成类别敏感语义图。为每一个可能包含目标的位置生成包含位类别的边界框。在没有锚框的限制下，FoveaBox可以有任意比例的边界框。

采用直接学习编码边界框的一般无锚策略，消除锚框对于检测性能的负面影响，并使用
基于语义信息的注意力机制平衡不同层次的多个特征，达到了最先进的性能。

##### 其它优化措施

过采样策略。对小目标样本充分采样。

级联思想。

分阶段检测。通过不同的层级之间的配合平衡漏检和误检之间的差异。

优化小目标检测的损失函数。避免遭受随机误差的影响。实现了小目标检测性能的提升。考虑前后景的不均衡问题。

### 优化的方向

特征融合的过程中要考虑到语义间隔和噪声干扰问题。如何消除特征融合过程中的噪音干扰。

针对小目标的上下文建模。

通过对抗的方式来提升小目标的特征，从而达到和一般目标同等的检测性能。







































