## TPH-YOLOv5: Improved YOLOv5 Based on Transformer Prediction Head for OD

核心思想：在yolo5的头部增加一个Transformer预测头，来利用自注意力机制在密集的场景中挖掘注意力区域。

具体使用到的方法有：数据增强，多尺度测试，多模型融合，以及额外的分类器。可以划分为以下几种方案：

1. 添加了多个预测头来预测不同的尺寸。
2. 将TPH融合到Yolov5中，能够在更密集的场景中更精确地定位对象。
3. 将CBAM融合到Yolov5中，能够帮助发现那些显著区域的部分。
4. 提供了一系列的tricks。
5. 使用自训练的分类器来提升一些比较复杂类的分类能力。

核心启发：

1. **多头以处理不同尺寸的对象。**

2. **同时混用CBAM和Transformer。**

### OD模型的组织划分

1. Backbone
   1. 直接使用经典backbone或者是针对特定任务的backbone.
   2. 关键使用到注意力模型，CBAM， 性能提升非常明显。
2. Neck
   1. 旁路集成或者其它特别的设计。
3. Head
   1. 一般用于分类和定位的精细调整，也分为单阶段网络或者是两阶段的网络。

### 使用Transformer

	1. 仅仅在head部分使用，增强特征交互与捕获能力。
 	2. 在分辨率比较低的层级使用，降低计算量确保可行。
 	3. transformer结构仅仅使用一层没有堆叠。

